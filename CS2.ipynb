{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKTWrbXjZ4kj19uRlOXmJD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vishnu-919/CS-Assignment2/blob/main/CS2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l918xg5d00CW",
        "outputId": "eeefa17d-acf9-48f8-9a7d-904bc3f27bbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting whois\n",
            "  Downloading whois-1.20240129.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading whois-1.20240129.2-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: whois\n",
            "Successfully installed whois-1.20240129.2\n"
          ]
        }
      ],
      "source": [
        "!pip install whois requests beautifulsoup4 scikit-learn pandas numpy matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import requests\n",
        "import whois\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "-WQSXgMZ0_U5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/dataset.csv')\n",
        "\n",
        "# Inspect first rows\n",
        "df.head(), df.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJfuV6UN1DFi",
        "outputId": "6cb6d43e-007b-468b-8d07-b45a04b4ccfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(   index  having_IPhaving_IP_Address  URLURL_Length  Shortining_Service  \\\n",
              " 0      1                          -1              1                   1   \n",
              " 1      2                           1              1                   1   \n",
              " 2      3                           1              0                   1   \n",
              " 3      4                           1              0                   1   \n",
              " 4      5                           1              0                  -1   \n",
              " \n",
              "    having_At_Symbol  double_slash_redirecting  Prefix_Suffix  \\\n",
              " 0                 1                        -1             -1   \n",
              " 1                 1                         1             -1   \n",
              " 2                 1                         1             -1   \n",
              " 3                 1                         1             -1   \n",
              " 4                 1                         1             -1   \n",
              " \n",
              "    having_Sub_Domain  SSLfinal_State  Domain_registeration_length  ...  \\\n",
              " 0                 -1              -1                           -1  ...   \n",
              " 1                  0               1                           -1  ...   \n",
              " 2                 -1              -1                           -1  ...   \n",
              " 3                 -1              -1                            1  ...   \n",
              " 4                  1               1                           -1  ...   \n",
              " \n",
              "    popUpWidnow  Iframe  age_of_domain  DNSRecord  web_traffic  Page_Rank  \\\n",
              " 0            1       1             -1         -1           -1         -1   \n",
              " 1            1       1             -1         -1            0         -1   \n",
              " 2            1       1              1         -1            1         -1   \n",
              " 3            1       1             -1         -1            1         -1   \n",
              " 4           -1       1             -1         -1            0         -1   \n",
              " \n",
              "    Google_Index  Links_pointing_to_page  Statistical_report  Result  \n",
              " 0             1                       1                  -1      -1  \n",
              " 1             1                       1                   1      -1  \n",
              " 2             1                       0                  -1      -1  \n",
              " 3             1                      -1                   1      -1  \n",
              " 4             1                       1                   1       1  \n",
              " \n",
              " [5 rows x 32 columns],\n",
              " (11055, 32))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Columns:\", df.columns.tolist())\n",
        "print(\"Unique labels:\", df['Result'].unique())  # may be “class” or “label”"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phiPloDw1waQ",
        "outputId": "7e0a97ca-8d2e-4fa3-cdf2-08cca2798307"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns: ['index', 'having_IPhaving_IP_Address', 'URLURL_Length', 'Shortining_Service', 'having_At_Symbol', 'double_slash_redirecting', 'Prefix_Suffix', 'having_Sub_Domain', 'SSLfinal_State', 'Domain_registeration_length', 'Favicon', 'port', 'HTTPS_token', 'Request_URL', 'URL_of_Anchor', 'Links_in_tags', 'SFH', 'Submitting_to_email', 'Abnormal_URL', 'Redirect', 'on_mouseover', 'RightClick', 'popUpWidnow', 'Iframe', 'age_of_domain', 'DNSRecord', 'web_traffic', 'Page_Rank', 'Google_Index', 'Links_pointing_to_page', 'Statistical_report', 'Result']\n",
            "Unique labels: [-1  1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_url_features(url):\n",
        "    features = {}\n",
        "    features['url_length'] = len(url)\n",
        "    features['num_digits'] = sum(c.isdigit() for c in url)\n",
        "    features['num_dots'] = url.count('.')\n",
        "    features['num_hyphens'] = url.count('-')\n",
        "    features['has_at'] = int('@' in url)\n",
        "    features['https'] = int(url.lower().startswith('https'))\n",
        "    features['num_subdirs'] = url.count('/')\n",
        "    # entropy\n",
        "    freq = [url.count(c)/len(url) for c in set(url)]\n",
        "    features['entropy'] = -sum([p * np.log2(p) for p in freq if p > 0])\n",
        "    return features\n",
        "\n",
        "def extract_html_features(url):\n",
        "    try:\n",
        "        resp = requests.get(url, timeout=5)\n",
        "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
        "        text = soup.get_text()\n",
        "        num_iframes = len(soup.find_all('iframe'))\n",
        "        num_forms = len(soup.find_all('form'))\n",
        "        num_scripts = len(soup.find_all('script'))\n",
        "    except Exception as e:\n",
        "        text = \"\"\n",
        "        num_iframes = 0\n",
        "        num_forms = 0\n",
        "        num_scripts = 0\n",
        "    return {\n",
        "        'text': text,\n",
        "        'num_iframes': num_iframes,\n",
        "        'num_forms': num_forms,\n",
        "        'num_scripts': num_scripts\n",
        "    }\n"
      ],
      "metadata": {
        "id": "zOGqDkMJ10Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "records = []\n",
        "numeric_cols = ['url_length','num_digits','num_dots','num_hyphens',\n",
        "                'has_at','https','num_subdirs','entropy',\n",
        "                'num_iframes','num_forms','num_scripts']\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    url = row['url']  # or whichever column holds URL\n",
        "    label = row['Result']\n",
        "    url_feats = extract_url_features(url)\n",
        "    html_feats = extract_html_features(url)\n",
        "    rec = {**url_feats, **html_feats, 'Result': label}\n",
        "    records.append(rec)\n",
        "\n",
        "feat_df = pd.DataFrame(records)\n",
        "feat_df.head(), feat_df.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "qsw_3ns-2HYB",
        "outputId": "b419b41f-d12c-45a0-8005-da854ac9a646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'url'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'url'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2804292631.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# or whichever column holds URL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Result'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0murl_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_url_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;31m# Convert generator to list before going through hashable part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'url'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(stop_words='english', max_features=500)\n",
        "X_text = tfidf.fit_transform(feat_df['text'])\n",
        "\n",
        "svd = TruncatedSVD(n_components=50)\n",
        "X_text_red = svd.fit_transform(X_text)\n",
        "\n",
        "X_num = feat_df[numeric_cols].fillna(0).values\n",
        "scaler = StandardScaler()\n",
        "X_num_scaled = scaler.fit_transform(X_num)\n",
        "\n",
        "X = np.hstack([X_num_scaled, X_text_red])\n",
        "y = feat_df['Result'].values\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "BszTWHwD2Jio",
        "outputId": "631ad6da-8137-4c6e-de02-3afe73496f6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'feat_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4062271212.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msvd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTruncatedSVD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_text_red\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'feat_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, stratify=y, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "Cd6JIDwK2sm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(64,32), max_iter=300, random_state=42)\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "mlp.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "HztiM-jV2tvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_pred = rf.predict_proba(X_train)[:,1]\n",
        "mlp_pred = mlp.predict_proba(X_train)[:,1]\n",
        "\n",
        "meta_X = np.vstack([rf_pred, mlp_pred]).T\n",
        "meta_model = LogisticRegression().fit(meta_X, y_train)\n",
        "\n",
        "rf_test = rf.predict_proba(X_test)[:,1]\n",
        "mlp_test = mlp.predict_proba(X_test)[:,1]\n",
        "meta_test = np.vstack([rf_test, mlp_test]).T\n",
        "\n",
        "final_pred = (meta_model.predict_proba(meta_test)[:,1] > 0.5).astype(int)\n"
      ],
      "metadata": {
        "id": "QNjDteRu2wD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\", accuracy_score(y_test, final_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, final_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, final_pred))"
      ],
      "metadata": {
        "id": "m_LaiYWn3AvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "importances = rf.feature_importances_[:len(numeric_cols)]\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.barh(numeric_cols, importances)\n",
        "plt.xlabel(\"Importance\")\n",
        "plt.title(\"Feature Importances (URL + HTML numeric features)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7V-Z4wKX22jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_url = \"http://secure-login-example-update.com\"\n",
        "url_feats = extract_url_features(new_url)\n",
        "html_feats = extract_html_features(new_url)\n",
        "rec = {**url_feats, **html_feats}\n",
        "num_part = scaler.transform([[rec[c] for c in numeric_cols]])\n",
        "text_vec = tfidf.transform([rec['text']])\n",
        "text_red = svd.transform(text_vec)\n",
        "X_new = np.hstack([num_part, text_red])\n",
        "\n",
        "rf_p = rf.predict_proba(X_new)[:,1]\n",
        "mlp_p = mlp.predict_proba(X_new)[:,1]\n",
        "meta_p = np.vstack([rf_p, mlp_p]).T\n",
        "pred_label = (meta_model.predict_proba(meta_p)[:,1] > 0.5).astype(int)[0]\n",
        "\n",
        "print(\"URL:\", new_url)\n",
        "print(\"Prediction:\", \"Phishing\" if pred_label == 1 else \"Legitimate\")\n"
      ],
      "metadata": {
        "id": "hhD1PwUs23hO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zZ5IKSlX25ua"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}